{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义逻辑斯蒂回归lf类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lf(object):\n",
    "    def __init__(self):\n",
    "        self.w = 0                  #权重\n",
    "        self.b = 0                  #截距\n",
    "        self.trainSet = 0           #训练集特征\n",
    "        self.label = 0              #训练集标签\n",
    "        self.learning_rate = 0.05   #学习率\n",
    "        self.n_iters = 1000         #实际迭代次数\n",
    "        self.accurancy = None       #准确率\n",
    "        self.tol = 0.001           #停止迭代的容忍度\n",
    "        self.llList = []            #记录似然值的列表\n",
    "    \n",
    "    def train(self, X, y, n_iters=1000, learning_rate=0.01):\n",
    "        self.trainSet = X\n",
    "        self.label = y\n",
    "        self.__train_gradient(n_iters, learning_rate)\n",
    "        return\n",
    "    \n",
    "    #求p(y=1|x)以及似然值LL\n",
    "    def PVandLLV(self, X, Y, W):\n",
    "        wx = np.dot(X, W.T) #点积\n",
    "        p_value = np.exp(wx) / (1 + np.exp(wx))\n",
    "        LLarray = -1.*np.multiply(Y, wx) + np.log(1 + np.exp(wx))\n",
    "        return p_value, LLarray.sum()\n",
    "    \n",
    "    #求梯度矩阵\n",
    "    def __calGradient(self, X, Y, Ypre):\n",
    "        Gw = -1.*np.multiply((Y - Ypre), X).sum(axis=0)\n",
    "        return Gw\n",
    "    \n",
    "    \n",
    "    def __train_gradient(self, n_iters, learning_rate):\n",
    "        n_samples, n_features = self.trainSet.shape\n",
    "        X = self.trainSet\n",
    "        y = self.label\n",
    "        #合并w和b，在X尾部添加一列全是1的特征\n",
    "        X2 = np.hstack((X, np.ones((n_samples, 1))))\n",
    "        #将y转置变为(n_samples,1)的矩阵\n",
    "        Y = np.expand_dims(y, axis=1)\n",
    "        #初始化特征系数W\n",
    "        W = np.zeros((1, n_features+1))\n",
    "        #初始化误差，更新前后的误差之差，训练次数\n",
    "        Ypreprob, LL0 = self.PVandLLV(X2, Y, W)\n",
    "        self.llList.append(LL0)\n",
    "        deltaLL = np.inf\n",
    "        n = 0\n",
    "        while (n < n_iters) and (LL0 > self.tol) and (abs(deltaLL) > self.tol):\n",
    "            #计算梯度，更新W\n",
    "            gra = self.__calGradient(X2, Y, Ypreprob)\n",
    "            W = W - learning_rate*gra / n_samples\n",
    "            #计算更新后的误差，并留下来\n",
    "            Ypreprob, LL1 = self.PVandLLV(X2, Y, W)\n",
    "            deltaLL = LL0 - LL1\n",
    "            LL0 = LL1\n",
    "            self.llList.append(LL0)\n",
    "            n += 1\n",
    "        self.n_iters = n\n",
    "        # flatten 返回一个一维数组\n",
    "        self.w = W.flatten()[:-1]\n",
    "        self.b = W.flatten()[-1]\n",
    "        Ypre = np.argmax(np.column_stack((1 - Ypreprob,Ypreprob)), axis=1)\n",
    "        self.accurancy = sum(Ypre==y) / n_samples\n",
    "        #print(\"迭代次数：{}，似然值：{}，准确率：{}\".format(self.n_iters, self.llList[-1], self.accurancy))\n",
    "        print(\"w:{}\\nb:{}\".format(self.w, self.b))\n",
    "        print(\"score:\",self.accurancy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:[-0.05957069  0.33460339 -0.03802806  1.8243648   0.42519204]\n",
      "b:0.0413666592885683\n",
      "score: 0.947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "if __name__ == \"__main__\":\n",
    "    # 自动生成数据\n",
    "    X, y = make_classification(n_samples=1000, n_features=5, random_state=123)\n",
    "    logit_gd = lf()\n",
    "    logit_gd.train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调用sklearn的LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:[-0.30739251  0.88326724 -0.11476345  4.2841313   0.91362391]\n",
      "b:0.46607030594821364\n",
      "score: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=5, random_state=123)\n",
    "logit_sklearn = LogisticRegression(solver=\"lbfgs\")\n",
    "logit_sklearn.fit(X, y)\n",
    "print(\"w:{}\\nb:{}\".format(logit_sklearn.coef_[0], logit_sklearn.intercept_[0]))\n",
    "print(\"score:\",logit_sklearn.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
